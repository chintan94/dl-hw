{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora,models\n",
    "from gensim.models import LdaModel\n",
    "from gensim.parsing.preprocessing import remove_stopwords,strip_punctuation, strip_numeric,strip_short\n",
    "import pandas as pd\n",
    "import unidecode\n",
    "import csv\n",
    "import datetime as dt\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/Users/anastasyatoropova/Downloads/amazon_reviews_us_Beauty_v1_00.tsv\"\n",
    "url = 'https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Beauty_v1_00.tsv.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anastasyatoropova/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "fdf = pd.read_csv(filename, delimiter='\\t', names=a[0], skiprows=[0])\n",
    "mask = fdf.isnull().sum(axis=1) != 7\n",
    "fdf = fdf[mask]\n",
    "fdf[\"review_date\"] = pd.to_datetime(fdf['review_date'],format = \"%Y-%m-%d\",errors='coerce')\n",
    "fdf.dropna(inplace=True)\n",
    "fdf[\"year\"] = fdf[\"review_date\"].map(lambda x: x.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_count = fdf.groupby('year')['review_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year\n",
       "2000         33\n",
       "2001        257\n",
       "2002        567\n",
       "2003       1252\n",
       "2004       3604\n",
       "2005       7889\n",
       "2006      11601\n",
       "2007      28486\n",
       "2008      39393\n",
       "2009      57243\n",
       "2010      95308\n",
       "2011     180718\n",
       "2012     342130\n",
       "2013     919622\n",
       "2014    1604463\n",
       "2015    1801244\n",
       "Name: review_id, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft1 = fdf[fdf[\"year\"] <= 2005]\n",
    "dft2 = fdf[(fdf[\"year\"] > 2005) & (fdf[\"year\"] <= 2009)]\n",
    "dft3 = fdf[(fdf[\"year\"] > 2009) & (fdf[\"year\"] <= 2012)]\n",
    "dft4 = fdf[fdf[\"year\"] > 2012]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(doc):\n",
    "    return(strip_short(remove_stopwords(strip_numeric(strip_punctuation(doc.lower()))),3).split())\n",
    "\n",
    "def lda_modeling_df(df):\n",
    "    tags = [tag for tag in df[\"review_body\"]]\n",
    "    corpus = [preprocess(tag) for tag in tags]\n",
    "    dictionary = corpora.Dictionary(corpus)\n",
    "    corpus = [dictionary.doc2bow(preprocess(tag)) for tag in tags]\n",
    "    dictionary.filter_extremes(no_below=2, no_above=0.99)\n",
    "    corpus = [dictionary.doc2bow(preprocess(tag)) for tag in tags]\n",
    "\n",
    "    lda_model = LdaModel(corpus=corpus,  # This code runs your lda\n",
    "                             id2word=dictionary, \n",
    "                             random_state=100, \n",
    "                             num_topics=15,\n",
    "                             passes=5,\n",
    "                             chunksize=10000,\n",
    "                             alpha='asymmetric',\n",
    "                             decay=0.5,\n",
    "                             offset=64,\n",
    "                             eta=None,\n",
    "                             eval_every=0,\n",
    "                             iterations=100,\n",
    "                             gamma_threshold=0.001,\n",
    "                             per_word_topics=True)\n",
    "    return lda_model, corpus, dictionary\n",
    "\n",
    "def print_lda_models(lda_model, dictionary):\n",
    "    for i in range(15):\n",
    "        words = lda_model.get_topic_terms(i, topn=10)\n",
    "        print(\"Topic : \" + str(i))\n",
    "        for i in words:\n",
    "            print(\"Word: \" + str(dictionary[i[0]]) + \"\\t\\t Weight: \" + str(i[1])) \n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic : 0\n",
      "Word: hair\t\t Weight: 0.04600167\n",
      "Word: product\t\t Weight: 0.013497666\n",
      "Word: use\t\t Weight: 0.011438107\n",
      "Word: time\t\t Weight: 0.00917726\n",
      "Word: like\t\t Weight: 0.008526855\n",
      "Word: great\t\t Weight: 0.007506492\n",
      "Word: dryer\t\t Weight: 0.0062313285\n",
      "Word: good\t\t Weight: 0.005978945\n",
      "Word: bought\t\t Weight: 0.0054621943\n",
      "Word: little\t\t Weight: 0.0050263167\n",
      "\n",
      "\n",
      "Topic : 1\n",
      "Word: like\t\t Weight: 0.016351992\n",
      "Word: product\t\t Weight: 0.011603008\n",
      "Word: great\t\t Weight: 0.00967996\n",
      "Word: use\t\t Weight: 0.008997925\n",
      "Word: love\t\t Weight: 0.008875364\n",
      "Word: scent\t\t Weight: 0.008587302\n",
      "Word: smell\t\t Weight: 0.0077008894\n",
      "Word: hair\t\t Weight: 0.0070929807\n",
      "Word: good\t\t Weight: 0.0062495875\n",
      "Word: smells\t\t Weight: 0.0055355644\n",
      "\n",
      "\n",
      "Topic : 2\n",
      "Word: use\t\t Weight: 0.0048875855\n",
      "Word: product\t\t Weight: 0.00443248\n",
      "Word: hair\t\t Weight: 0.0040734205\n",
      "Word: skin\t\t Weight: 0.0037887916\n",
      "Word: like\t\t Weight: 0.0036230092\n",
      "Word: clean\t\t Weight: 0.002614089\n",
      "Word: great\t\t Weight: 0.002436231\n",
      "Word: razor\t\t Weight: 0.0023274005\n",
      "Word: new\t\t Weight: 0.002086022\n",
      "Word: good\t\t Weight: 0.001973179\n",
      "\n",
      "\n",
      "Topic : 3\n",
      "Word: humidifier\t\t Weight: 0.004945958\n",
      "Word: hair\t\t Weight: 0.0046050423\n",
      "Word: eye\t\t Weight: 0.0036139486\n",
      "Word: skin\t\t Weight: 0.0034873006\n",
      "Word: use\t\t Weight: 0.0031230103\n",
      "Word: product\t\t Weight: 0.0030128362\n",
      "Word: works\t\t Weight: 0.002808021\n",
      "Word: feet\t\t Weight: 0.0027019915\n",
      "Word: dry\t\t Weight: 0.0025665683\n",
      "Word: like\t\t Weight: 0.002465409\n",
      "\n",
      "\n",
      "Topic : 4\n",
      "Word: skin\t\t Weight: 0.020002497\n",
      "Word: shave\t\t Weight: 0.013012019\n",
      "Word: use\t\t Weight: 0.012362352\n",
      "Word: shaver\t\t Weight: 0.012089277\n",
      "Word: product\t\t Weight: 0.011256291\n",
      "Word: razor\t\t Weight: 0.010844728\n",
      "Word: face\t\t Weight: 0.009006053\n",
      "Word: like\t\t Weight: 0.0083974395\n",
      "Word: good\t\t Weight: 0.0071833576\n",
      "Word: great\t\t Weight: 0.006739398\n",
      "\n",
      "\n",
      "Topic : 5\n",
      "Word: hair\t\t Weight: 0.0055864137\n",
      "Word: product\t\t Weight: 0.0038737734\n",
      "Word: like\t\t Weight: 0.0027915975\n",
      "Word: skin\t\t Weight: 0.0026941022\n",
      "Word: time\t\t Weight: 0.0021068098\n",
      "Word: dry\t\t Weight: 0.0020654488\n",
      "Word: use\t\t Weight: 0.0020007836\n",
      "Word: tried\t\t Weight: 0.0015970159\n",
      "Word: brush\t\t Weight: 0.0015909487\n",
      "Word: great\t\t Weight: 0.0014147022\n",
      "\n",
      "\n",
      "Topic : 6\n",
      "Word: skin\t\t Weight: 0.0034660688\n",
      "Word: use\t\t Weight: 0.0032398026\n",
      "Word: product\t\t Weight: 0.0028114673\n",
      "Word: laura\t\t Weight: 0.002610286\n",
      "Word: like\t\t Weight: 0.002551749\n",
      "Word: foundation\t\t Weight: 0.002398344\n",
      "Word: good\t\t Weight: 0.0021832073\n",
      "Word: face\t\t Weight: 0.0020727825\n",
      "Word: cotton\t\t Weight: 0.0020269891\n",
      "Word: little\t\t Weight: 0.0019476637\n",
      "\n",
      "\n",
      "Topic : 7\n",
      "Word: use\t\t Weight: 0.0013810026\n",
      "Word: skin\t\t Weight: 0.0013448077\n",
      "Word: like\t\t Weight: 0.001237455\n",
      "Word: time\t\t Weight: 0.0010131466\n",
      "Word: product\t\t Weight: 0.001010697\n",
      "Word: transparency\t\t Weight: 0.0008972888\n",
      "Word: hair\t\t Weight: 0.0007954794\n",
      "Word: thou\t\t Weight: 0.00070409256\n",
      "Word: little\t\t Weight: 0.00063151505\n",
      "Word: love\t\t Weight: 0.00061799947\n",
      "\n",
      "\n",
      "Topic : 8\n",
      "Word: shaver\t\t Weight: 0.0028113439\n",
      "Word: skin\t\t Weight: 0.0025648633\n",
      "Word: great\t\t Weight: 0.0023014678\n",
      "Word: product\t\t Weight: 0.001710954\n",
      "Word: like\t\t Weight: 0.0016482123\n",
      "Word: love\t\t Weight: 0.0012673574\n",
      "Word: smells\t\t Weight: 0.0012467722\n",
      "Word: use\t\t Weight: 0.0011236197\n",
      "Word: hair\t\t Weight: 0.001101245\n",
      "Word: good\t\t Weight: 0.0010768478\n",
      "\n",
      "\n",
      "Topic : 9\n",
      "Word: shaver\t\t Weight: 0.003581135\n",
      "Word: cleaning\t\t Weight: 0.0028022106\n",
      "Word: braun\t\t Weight: 0.0025188832\n",
      "Word: use\t\t Weight: 0.0024786475\n",
      "Word: product\t\t Weight: 0.0019107818\n",
      "Word: good\t\t Weight: 0.001753168\n",
      "Word: time\t\t Weight: 0.0017022068\n",
      "Word: razor\t\t Weight: 0.001672845\n",
      "Word: shave\t\t Weight: 0.0016501525\n",
      "Word: like\t\t Weight: 0.0015476855\n",
      "\n",
      "\n",
      "Topic : 10\n",
      "Word: teeth\t\t Weight: 0.019920269\n",
      "Word: brush\t\t Weight: 0.017791\n",
      "Word: toothbrush\t\t Weight: 0.014187764\n",
      "Word: use\t\t Weight: 0.010168546\n",
      "Word: sonicare\t\t Weight: 0.010092119\n",
      "Word: product\t\t Weight: 0.008849224\n",
      "Word: dentist\t\t Weight: 0.007918911\n",
      "Word: like\t\t Weight: 0.006726349\n",
      "Word: gums\t\t Weight: 0.0058454564\n",
      "Word: clean\t\t Weight: 0.0057182233\n",
      "\n",
      "\n",
      "Topic : 11\n",
      "Word: oil\t\t Weight: 0.014992266\n",
      "Word: lavender\t\t Weight: 0.010055039\n",
      "Word: skin\t\t Weight: 0.008786739\n",
      "Word: vitamin\t\t Weight: 0.0074450304\n",
      "Word: lips\t\t Weight: 0.007265926\n",
      "Word: product\t\t Weight: 0.0066798856\n",
      "Word: extract\t\t Weight: 0.0066311443\n",
      "Word: organic\t\t Weight: 0.00629551\n",
      "Word: essential\t\t Weight: 0.0057511744\n",
      "Word: lip\t\t Weight: 0.0055481684\n",
      "\n",
      "\n",
      "Topic : 12\n",
      "Word: great\t\t Weight: 0.0020362632\n",
      "Word: like\t\t Weight: 0.001405921\n",
      "Word: product\t\t Weight: 0.0013015895\n",
      "Word: skin\t\t Weight: 0.0011899649\n",
      "Word: scent\t\t Weight: 0.0011001562\n",
      "Word: fragrance\t\t Weight: 0.00085881125\n",
      "Word: smell\t\t Weight: 0.0008326812\n",
      "Word: time\t\t Weight: 0.0008286285\n",
      "Word: good\t\t Weight: 0.000818305\n",
      "Word: love\t\t Weight: 0.0007971544\n",
      "\n",
      "\n",
      "Topic : 13\n",
      "Word: hair\t\t Weight: 0.0024260322\n",
      "Word: product\t\t Weight: 0.0024195584\n",
      "Word: like\t\t Weight: 0.002034997\n",
      "Word: use\t\t Weight: 0.0017849333\n",
      "Word: little\t\t Weight: 0.0011915468\n",
      "Word: great\t\t Weight: 0.0011692456\n",
      "Word: time\t\t Weight: 0.0011346976\n",
      "Word: work\t\t Weight: 0.00091261615\n",
      "Word: skin\t\t Weight: 0.0008710986\n",
      "Word: bought\t\t Weight: 0.0008653998\n",
      "\n",
      "\n",
      "Topic : 14\n",
      "Word: like\t\t Weight: 0.003155193\n",
      "Word: skin\t\t Weight: 0.002582348\n",
      "Word: great\t\t Weight: 0.0021465342\n",
      "Word: good\t\t Weight: 0.0021216248\n",
      "Word: product\t\t Weight: 0.0019352271\n",
      "Word: scent\t\t Weight: 0.0018466199\n",
      "Word: use\t\t Weight: 0.0015274375\n",
      "Word: time\t\t Weight: 0.0012638243\n",
      "Word: little\t\t Weight: 0.001109753\n",
      "Word: day\t\t Weight: 0.0009900309\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lda_model, corpus, dictionary = lda_modeling_df(dft1)\n",
    "print_lda_models(lda_model, dictionary)\n",
    "\n",
    "lda_model.log_perplexity(corpus)\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, dictionary)\n",
    "pyLDAvis.show(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model.log_perplexity(corpus)\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, dictionary)\n",
    "pyLDAvis.show(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model2, corpus2, dictionary2 = lda_modeling_df(dft2)\n",
    "print_lda_models(lda_model2, dictionary2)\n",
    "\n",
    "lda_model2.log_perplexity(corpus2)\n",
    "vis2 = pyLDAvis.gensim.prepare(lda_model2, corpus2, dictionary2)\n",
    "pyLDAvis.show(vis2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model3, corpus3, dictionary3 = lda_modeling_df(dft3)\n",
    "print_lda_models(lda_model3, dictionary3)\n",
    "\n",
    "lda_model3.log_perplexity(corpus3)\n",
    "vis3 = pyLDAvis.gensim.prepare(lda_model3, corpus3, dictionary3)\n",
    "pyLDAvis.show(vis3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model4, corpus4, dictionary4 = lda_modeling_df(dft4)\n",
    "print_lda_models(lda_model4, dictionary4)\n",
    "\n",
    "lda_model4.log_perplexity(corpus4)\n",
    "vis4 = pyLDAvis.gensim.prepare(lda_model4, corpus4, dictionary4)\n",
    "pyLDAvis.show(vis4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
