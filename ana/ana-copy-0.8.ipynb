{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora,models\n",
    "from gensim.models import LdaModel\n",
    "from gensim.parsing.preprocessing import remove_stopwords,strip_punctuation, strip_numeric,strip_short\n",
    "import pandas as pd\n",
    "import unidecode\n",
    "import csv\n",
    "import datetime as dt\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"amazon_reviews_us_Beauty_v1_00.tsv\"\n",
    "url = 'https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Beauty_v1_00.tsv.gz'\n",
    "\n",
    "a = [] \n",
    "with open(filename) as tsvfile:\n",
    "    reader = csv.reader(tsvfile, delimiter='\\t' )\n",
    "    for row in reader:\n",
    "        a.append(row)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf = pd.read_csv(filename, delimiter='\\t', names=a[0], skiprows=[0])\n",
    "mask = fdf.isnull().sum(axis=1) != 7\n",
    "fdf = fdf[mask]\n",
    "fdf[\"review_date\"] = pd.to_datetime(fdf['review_date'],format = \"%Y-%m-%d\",errors='coerce')\n",
    "fdf.dropna(inplace=True)\n",
    "fdf[\"year\"] = fdf[\"review_date\"].map(lambda x: x.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_count = fdf.groupby('year')['review_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_count = year_count.to_dict()\n",
    "year_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Partition logic\n",
    "#30000 random entries per year\n",
    "\n",
    "years = list(year_count.keys())\n",
    "years.remove(2000)\n",
    "df_list = []\n",
    "thresh = 30000\n",
    "for year in years:\n",
    "    temp_df = fdf[fdf[\"year\"] == year]\n",
    "    if (year_count[year] > thresh):\n",
    "        temp_df = temp_df.sample(thresh)\n",
    "    df_list.append(temp_df)    \n",
    "\n",
    "\n",
    "concat_dfs = []\n",
    "for i in range(5):\n",
    "    concat_dfs.append(pd.concat(df_list[3 * i: 3 * i + 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(doc):\n",
    "    return(strip_short(remove_stopwords(strip_numeric(strip_punctuation(doc.lower()))),3).split())\n",
    "\n",
    "def lda_modeling_df(df):\n",
    "    tags = [tag for tag in df[\"review_body\"]]\n",
    "    corpus = [preprocess(tag) for tag in tags]\n",
    "    dictionary = corpora.Dictionary(corpus)\n",
    "    corpus = [dictionary.doc2bow(preprocess(tag)) for tag in tags]\n",
    "    dictionary.filter_extremes(no_below=2, no_above=0.8)\n",
    "    corpus = [dictionary.doc2bow(preprocess(tag)) for tag in tags]\n",
    "\n",
    "    lda_model = LdaModel(corpus=corpus,  # This code runs your lda\n",
    "                             id2word=dictionary, \n",
    "                             random_state=100, \n",
    "                             num_topics=15,\n",
    "                             passes=5,\n",
    "                             chunksize=10000,\n",
    "                             alpha='asymmetric',\n",
    "                             decay=0.5,\n",
    "                             offset=64,\n",
    "                             eta=None,\n",
    "                             eval_every=0,\n",
    "                             iterations=100,\n",
    "                             gamma_threshold=0.001,\n",
    "                             per_word_topics=True)\n",
    "    return lda_model, corpus, dictionary\n",
    "\n",
    "def print_lda_models(lda_model, dictionary):\n",
    "    for i in range(15):\n",
    "        words = lda_model.get_topic_terms(i, topn=10)\n",
    "        print(\"Topic : \" + str(i))\n",
    "        for i in words:\n",
    "            print(\"Word: \" + str(dictionary[i[0]]) + \"\\t\\t Weight: \" + str(i[1])) \n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model, corpus, dictionary = lda_modeling_df(concat_dfs[0])\n",
    "print_lda_models(lda_model, dictionary)\n",
    "\n",
    "lda_model.log_perplexity(corpus)\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, dictionary)\n",
    "pyLDAvis.display(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model2, corpus2, dictionary2 = lda_modeling_df(concat_dfs[1])\n",
    "print_lda_models(lda_model2, dictionary2)\n",
    "\n",
    "lda_model2.log_perplexity(corpus2)\n",
    "vis2 = pyLDAvis.gensim.prepare(lda_model2, corpus2, dictionary2)\n",
    "pyLDAvis.display(vis2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model3, corpus3, dictionary3 = lda_modeling_df(concat_dfs[2])\n",
    "print_lda_models(lda_model3, dictionary3)\n",
    "\n",
    "lda_model3.log_perplexity(corpus3)\n",
    "vis3 = pyLDAvis.gensim.prepare(lda_model3, corpus3, dictionary3)\n",
    "pyLDAvis.display(vis3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model4, corpus4, dictionary4 = lda_modeling_df(concat_dfs[3])\n",
    "print_lda_models(lda_model4, dictionary4)\n",
    "\n",
    "lda_model4.log_perplexity(corpus4)\n",
    "vis4 = pyLDAvis.gensim.prepare(lda_model4, corpus4, dictionary4)\n",
    "pyLDAvis.display(vis4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model5, corpus5, dictionary5 = lda_modeling_df(concat_dfs[4])\n",
    "print_lda_models(lda_model5, dictionary5)\n",
    "\n",
    "lda_model5.log_perplexity(corpus5)\n",
    "vis5 = pyLDAvis.gensim.prepare(lda_model5, corpus5, dictionary5)\n",
    "pyLDAvis.display(vis5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flda_model, fcorpus, fdictionary = lda_modeling_df(pd.concat(concat_dfs))\n",
    "print_lda_models(flda_model, fdictionary)\n",
    "\n",
    "flda_model.log_perplexity(fcorpus)\n",
    "fvis = pyLDAvis.gensim.prepare(flda_model, fcorpus, fdictionary)\n",
    "pyLDAvis.display(fvis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
