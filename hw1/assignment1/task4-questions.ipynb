{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECBM E4040 Assignment 1, Task 4: Questions\n",
    "1) Cross entropy is a metric that measures the \"distance\" between two distributions, why can it be used in calculating the loss of softmax classifier? \n",
    "\n",
    "   Your answer: \n",
    "   \n",
    "Softmax classifier is the generalization of binary Logistic Regression classifier. Unlike SVM which treats the outputs as scores for each class, the softmax classifier has a probabilistic interpretation, where the function mapping stays unchanged, but we now interpret these scores as unnormalized log probabilties for each class and replace the hinge loss with cross-entropy loss. The softmax classifier is thus minimizing the cross-entropy between the estimated class probabilities and the \"true distribution\".\n",
    "\n",
    "\n",
    "2) How does binary SVM classifier deal with multi-class classification problem? In general, there are two ways.Please describe both training process and inference process of different methods.\n",
    "\n",
    "   Your answer:\n",
    "\n",
    "1)The one-versus-rest approach constructs k seperate binary classifiers for k-class classification. \n",
    "    Training: n-th binary classifier is trained using the data from the n-th class as positive and the remaining classes as negative examples. \n",
    "    Test: The class label is determined by the binary classifier that gives maximum output value.\n",
    "2)The one-versus-one or pairwise decomposition evaluates all possible pairwise classifiers and thus induces k(k-1)/2 individual binary classifiers. Applying each classifiers to a test example would give one vote to the winning class. A test example is labeled to the class with the most votes.\n",
    "   \n",
    "\n",
    "3) What are the pros and cons of SVM compared with MLP?\n",
    "\n",
    "   Your answer: \n",
    "   \n",
    "SVM performs better when one boundary seperates classes. MLP is better than SVM when multiple boundaries are required. Because MLP can model XORs.\n",
    "      \n",
    "4) Why is the ReLU activation function used the most often in neural networks for computer vision?\n",
    "\n",
    "   Your answer:\n",
    "\n",
    "1)The non-saturation of gradient. It accelerates the convergenece of SGD compared to sigmoid or tanh functions. \n",
    "2)Sparsity. This arises when Wx + b <= 0. The more such units that exist in a layer the more sparse the resulting representation, while sigmoids generate some non-zero value resulting in dense representations.\n",
    "   \n",
    "   \n",
    "5) Describe your best model in the implementation of the two-layer neural network. Describe your starting point, how you tuned  hyperparameters, which stategies you used to improve the network, show the results of intermediate and the final steps.\n",
    "\n",
    "   Your answer: \n",
    "\n",
    "Accuracy 51.18%. I achieved this by tuning my num_epochs to 20.\n",
    "   \n",
    "model = TwoLayerNet(input_dim=3072, hidden_dim=100, num_classes=10, reg=0.35, weight_scale=5e-3)\n",
    "\n",
    "num_epoch = 20\n",
    "batch_size = 500\n",
    "lr = 1e-3\n",
    "verbose = True\n",
    "   \n",
    "\n",
    "6) **Cross validation** is a technique used to prove the generalization ability of a model and can help you find a robust set of hyperparameters. Please describe the implementation details of **k-fold cross validation**.\n",
    "\n",
    "   Your answer: \n",
    "   \n",
    "Sample is divided into k subsamples. Train the model on all but one subsample. Use the remaining subsample as validation set. Repeat this process until all the subsamples are used as a validation set. Validation error is the average of all the validation errors. Least validation error provides the best set of hyperparameters.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
